---
title: "[MMP] 同步和多处理器问题"
date: 2017-08-11 15:15:38
categories: [学习笔记, MMP]  
tags: MMP
---
这里是我看了多篇相关文章记的笔记mix。掺杂一些（其实很多）自己的理解。

# 简要描述  
程序在多核系统上运行时可能会遇到问题，因为它们所做的假设仅在单处理器系统上有效。
在多处理器系统，优先级不同的程序可以在各自的处理器上同时运行，假设高优先级线程运行不受低优先级线程干扰的代码在多处理器系统上会失效。

当处理器将数据写入内存位置时，会缓存该数据以提高性能；当读取某内存位置时，处理器会从缓存中读取以提高性能。  
在多处理器时，当内存位置由不同的处理器读取或写入时，可能数据在缓存中没有写入内存或跟其它处理器同步，这样在取数据时，各处理器得到的数据就有所差异，而某些时候如果处理器频繁同步cache会造成一定的性能损耗。  
为了确保内存操作顺序完成，大多数处理器提供内存栅栏指令。完整的内存栅栏指令可以确保在栅栏之前的内存读写操作先于其它任何后于栅栏的指令被提交到内存中。读写栅栏各限制读写内存指令。这些指令还确保编译器禁用指令重排等跨栅栏内存操作的各种优化。  

栅栏语义有acquire、release等。acquire确保该操作结果在后面代码中出现的其它任何操作结果之前可用，release确保操作结果在前面代码中出现的操作结果之后可用。

**关于正确性**
不确保记录的完全正确。

一说在X86/64架构处理器上的内存模型默认就是顺序一致(seq_cst)的，也就是说无法引发这类一致性问题。


boost里（在load的时候）也有如下注释：
>On x86 and x86_64 there is no need for a hardware barrier, even if seq_cst memory order is requested, because all seq_cst writes are implemented with lock-prefixed operations or xchg which has implied lock prefix. Therefore normal loads are already ordered with seq_cst stores on these architectures.

在x86/64的机子上，即使请求了`seq_cst`也不需要硬件栅栏，因为所有写入操作都是用锁定前缀或者用隐含锁定前缀的xchg实现的。因此，在这类架构中加载时已经使用了`seq_cst`顺序。

不过[这里](https://msdn.microsoft.com/zh-cn/data/ms686355)写：

>On Intel Itanium-based systems, the instruction is mf (memory fence) with the following modifiers: acq (acquire) and rel (release). On processors that support SSE2, the instructions are mfence (memory fence), lfence (load fence), and sfence (store fence). For more information, see the documentation for the processor.

在基于Intel Itanium架构的系统上，内存栅栏的指令是mf，带有acq、rel语义。在支持SSE2的处理器上，内存栅栏的指令是mfence，载入栅栏是lfence，存储栅栏是sfence。

相关指令在winnt.h中定义如下：
```cpp
#define FastFence __faststorefence
#define MemoryBarrier __faststorefence
#define StoreFence _mm_sfence
#define LoadFence _mm_lfence
#define MemoryFence _mm_mfence
```
系统中有相应的指令（说明在x86/64的机子上是有可能引发这类问题的），但是我不知道如何使用它们（msdn没有例子）。

所以此篇笔记一些部分（栅栏语义）的正确性我无法通过代码测试确保，只能通过查看多篇文章认定这么表述可能正确。所以我知道会有这个问题也知道可能这么编才正确，但我无法重现错误的场景，这可能更像一种玄学……只能再继续学等超过现在的水平了再修复这篇笔记错误的地方。  

**引发的问题**
一般文章中记录的例子都是：

线程 A                     |  线程 B
-------------------------- | -----------------------------
val = 1; <br/>flag = true; | while(!flag);<br/> test(val);

在test(val)时可能获取到的是旧值。原因就是下面的内容。   

# Race Condition
## 内存模型
**输入一定的内存操作序列，得到一定的内存结果，这种对应关系的集合，就是内存模型，任何一种CPU架构，都有该架构对应的内存模型**。
C++03前没有定义并发环境下的内存模型，之前的模型只适用单线程。之前模型在并发环境下，在不同编译器、环境、硬件平台上得到的内存结果可能会不一样。

### 缓存一致性
cpu处理数据前会把数据载入到cache line里，而每个核心都有自己的缓存，如果多个缓存引用了相同的内存位置，在并发执行时，如果有些数据刚在缓存中修改并没有将更新写入到内存中，这样其它核心得到的数据将会是修改前的数据。缓存一致性确保其它核心能取得这修改后的数据。  
单核没有这种问题是因为cache只有一个，再怎么改都能得到最新数据。  

### 顺序一致性
方法调用应该呈现出按照次序调用的执行效果。  
cpu实际执行的指令序列与源代码的语句序列有区别，因为在现代处理器中，存储器的读写都不是顺序一致性的，这些操作会被重排，在需要顺序的时候必须显式指定。  
顺序一致性不可复合，复合在一起不能保持顺序一致性。  

会导致重排的原因有：
编译器优化，比如为了优化缓存效率把load集中在一起，或者提升效率将数据载入寄存器；这会使源代码顺序和编译出的机器码顺序不一致。
cpu执行优化，乱序执行，操作数预取等；这会导致机器码顺序和执行顺序不一致，各核心观察到的总体指令也会不一致，因为内存的改变顺序不一致，这与同步策略有关。

### 静态一致性
方法调用以某种顺序执行，且每个时刻只有一个调用发生。  
由一系列静止状态分隔开的方法调用且呈现出按照它们实时调用次序相同的执行结果。  

## 内存序
### synchronizes with
多核情况下，如果某核心对内存变量做出修改，在其它核心能立即观察到，那么变量就具有这个属性；通过观察这个变量的变化顺序，便可以得到核心之间执行指令的顺序，这样就可以得到happens before关系。

### happens before
多核情况，如果某指令能确保在另一指令之前运行，就对另一指令具有这个属性。这个关系可能会与观测者有关。  
简单来说就是，后面的指令能观察到前面指令引起的变化。这个关系是可以在多个线程间传递的（inter-thread happens before）。


### 栅栏（屏障）
由于编译器的优化和缓存的使用，导致对内存的写入操作不能及时的反应出来，也就是说当完成对内存的写入操作之后，其它核心读取出来的可能是旧的内容。
栅栏保证语句前后代码具有happens before的关系，这样可以避免指令重排（防止cpu或编译器重组指令）引发的问题（使某些后面的操作先于前面的操作）。

其作用是：
在其它处理器执行加载或存储操作前，必须先执行所有先前的获取（acquire）访问。  
在其它处理器执行release前，必须先执行所有先前的加载和存储访问。  
获取和释放是顺序一致的（在全局范围内和acq rel）；在acq前和rel后允许正常加载和存储操作重排。

分类：
编译器屏障
缓存屏障
乱序执行屏障

### 语义
这里需要配合stl的atomic来说明。  
atomic定义了几种内存排序模型
```
    seq_cst
        |
    acq_rel
    /     \
acquire  release
    |       |
consume    |
    \     /
    relaxed
```
atomic的load操作不能用`memory_order_release`、`memory_order_acq_rel`，因为逻辑不符；同样的，store不能用`memory_order_acquire`、`memory_order_consume`、`memory_order_acq_rel`。

虽然内存顺序有六个选项，但是它们仅代表三种内存模型：排序一致序列(sequentially consistent)，获取-释放序列(`memory_order_consume`, `memory_order_acquire`, `memory_order_release`和`memory_order_acq_rel`)，和自由序列(`memory_order_relaxed`)。

_以下的代码分析是在x86/64环境（编译器是msvc）下进行（没有arm环境），能分析到的东西有限，而且也不代表其它的环境也是这样的，这里只用于辅助理解。_

#### memory_order_relaxed

**Load**
stl关键代码如下：
```cpp
inline _Uint4_t _Load_relaxed_4(volatile _Uint4_t *_Tgt)
{	/* load from *_Tgt atomically with
	relaxed memory order */
	_Uint4_t _Value;

#if defined(_M_ARM) || defined(_M_ARM64)
	_Value = __iso_volatile_load32((volatile int *)_Tgt);

#else
	_Value = *_Tgt;
#endif

	return (_Value);
}
```
就是直接对volatile指针（这里是用来防止被编译器优化掉，其本身是有序的，但是在多核情况不能保证）取数据。  

boost的相应代码是：
```cpp
static BOOST_FORCEINLINE storage_type load(storage_type const volatile& storage, memory_order order) BOOST_NOEXCEPT
{
    storage_type v = storage;
    fence_after_load(order);
    return v;
}
```
storage_type 是atomic的参数类型。`fence_after_load`执行的是`BOOST_ATOMIC_DETAIL_COMPILER_BARRIER`，定义如下：
```cpp
#if defined(__INTEL_COMPILER)
#define BOOST_ATOMIC_DETAIL_COMPILER_BARRIER() __memory_barrier()
#elif defined(_MSC_VER) && !defined(_WIN32_WCE)
extern "C" void _ReadWriteBarrier(void);
#pragma intrinsic(_ReadWriteBarrier)
#define BOOST_ATOMIC_DETAIL_COMPILER_BARRIER() _ReadWriteBarrier()
#endif
```
这里调用到编译器内部函数，不好做出判断。  
在gcc下stl和boost最终用的都是`__atomic_load_n`，无法看更详细的内容（不想再找相关源码）。因为gcc下编译最终都会直接调用到内部函数，所以后面不贴gcc下编译的代码。    

**Store**
stl：
```cpp
/* _Atomic_store_4 */
inline void _Store_relaxed_4(volatile _Uint4_t *_Tgt, _Uint4_t _Value)
{	/* store _Value atomically with relaxed memory order */

#if defined(_M_ARM) || defined(_M_ARM64)
	__iso_volatile_store32((volatile int *)_Tgt, _Value);

#else
	*_Tgt = _Value;
#endif
}
```
直接存储数据。

boost的不管是什么选项（除了`seq_cst`直接用原子操作）都在存取前后加栅栏（msvc编译器下），后面不再贴boost的store代码。  

**其它**
比如fetch、compare_exchange，内部都直接用原子操作，只有在arm时才用特别的编译器内部函数。所以这里代码（及之后这里的代码）略。    

**总结**
这个语义不保证任何顺序，这点可以从stl看出。  


#### memory_order_acquire
**Load**
stl:
```cpp
/* _Atomic_load_4 */
inline _Uint4_t _Load_seq_cst_4(volatile _Uint4_t *_Tgt)
{	/* load from *_Tgt atomically with
	sequentially consistent memory order */
	_Uint4_t _Value;

#if defined(_M_ARM) || defined(_M_ARM64)
	_Value = __iso_volatile_load32((volatile int *)_Tgt);
	_Memory_barrier();

#else
	_Value = *_Tgt;
	_Compiler_barrier();
#endif

	return (_Value);
}
```
`_Compiler_barrier`是内部函数`_ReadWriteBarrier`。
这里是**先取数据再放栅栏**。

经优化后什么都没有，就是一般的取值指令：
```asm
 std::atomic<int> num(0);
 mov         dword ptr [rsp+8],0  
 return num.load(flagstl);
 mov         eax,dword ptr [rsp+8] 
```

boost的代码跟relax一样。

**Store**
没有acq语义。  



**总结**
先取数据再栅栏，这样保证了取得的数据先于后面的代码（在后面的代码前生效），后面的代码可以观察到该数据的最新值。其实不止这个数据，栅栏之前的数据也都能观察到最新值。  

#### memory_order_consume
store不能使用。  
在msvc环境，stl源码中的consume执行路径跟acquire完全一样。  
这个原本的语义是让依赖于数据的代码有序（其它不处理），在大多数平台上只影响编译器优化。  
但看源码的写法，其实是无所谓的。  

#### memory_order_release
**Load**
没有

**Store**
stl：
```cpp
inline void _Store_release_4(volatile _Uint4_t *_Tgt, _Uint4_t _Value)
{	/* store _Value atomically with release memory order */

#if defined(_M_ARM) || defined(_M_ARM64)
	_Memory_barrier();
	__iso_volatile_store32((volatile int *)_Tgt, _Value);

#else
	_Compiler_barrier();
	*_Tgt = _Value;
#endif
}
```
先栅栏再将值写入。

这里放未优化的代码（因为release的就是简单的取值赋值）：
```asm
 ...
	_Compiler_barrier();
	*_Tgt = _Value;
 mov         rax,qword ptr [_Tgt]  
 mov         ecx,dword ptr [_Value]  
 mov         dword ptr [rax],ecx  
 ...
```
可以看到，在debug选项下也并没有调用到什么栅栏的指令。所以更确定前面说的，**在x86/64架构上，不需要明确设置这些语义**。  

而如果用到前面提到的sse2指令的话（不会用这类指令，不知道这么表述对不对）会添加这些指令：
```cpp
	FastFence();
 lock or     dword ptr [rsp],eax  
	MemoryBarrier();
 lock or     dword ptr [rsp],eax  
	MemoryFence();
 mfence  
	LoadFence();
 lfence  
	StoreFence();
 sfence 
```


**总结**
先栅栏，再存储值。保证这个存储操作不会先于前面的代码生效（限制前后顺序）。

#### memory_order_acq_rel
load、store都不能使用。
fetch和exchange都是用原子操作函数（前面提到具有`seq_cst`语义，所以执行路径跟`seq_cst`一样）。  
这个语义是同时包含acq、rel。

#### memory_order_seq_cst
load的执行路径跟acq的一样。
store的直接用原子操作函数。
fetch和exchange跟acq_rel一样。
作用是全部按顺序运行。

### 传递依赖
各依赖是可以传递的，比如：
A release a
B consume a
b 依赖 a
B release b
C consume 或 acquire b
此时 AB、BC同步 AC经过传递也同步

注意，这个传递会遍及涉及到的线程，可能会影响性能

当acq或consume时可能会携带依赖，这时候如果想避免这部分开销（编译器会重新读这部分内容，避免开销比如让编译器在寄存器中缓存），可以使用std::kill_dependecy,显式打破依赖，比如有一个只读数组不需要重新读取时：
```cpp
int global_data[]={ … };
std::atomic<int> index;

void f()
{
  int i=index.load(std::memory_order_consume);
  // 这里由于i，取数组内容时会携带依赖
  do_something_with(global_data[std::kill_dependency(i)]);
}
```
其定义如下：
```cpp
// TEMPLATE FUNCTION kill_dependency
template<class _Ty>
_Ty kill_dependency(_Ty _Arg) _NOEXCEPT
{	// magic template that kills dependency ordering when called
	return (_Arg);
}
```
原理不明（估计可以用汇编分析出来，但是在我现在用的环境下可能不行）。  

## 总结
简单来说就是load的时候acq，store的时候rel，适时用consume，不在乎就用acqrel或seqcst；在x86/64就用默认（不填）就行了。_（所以Go中的原子操作并不需要设置这些）_

另外volatile的作用是**提醒编译器它后面所定义的变量随时都有可能改变**，因此编译后的程序每次需要存储或读取这个变量的时候，都会直接从变量地址中读取数据。  
如果没有volatile关键字，则编译器可能优化读取和存储，可能暂时使用寄存器中的值，如果这个变量由别的程序更新了的话，将出现不一致的现象。
编译器不会重排volatile，但是处理器会重排它，在多核情况是不能用于限定顺序的。  



# 其它一些问题
## 乒乓缓存
多核线程在同时读+写某个变量（甚至是互斥量）时，需要等待另一核线程修改值的缓存更新才能进行操作，这时候两个线程就有一段互相等待对方缓存更新的时间。  
修改程序结构可以避开这种情况（需要具体情况具体分析）。  

## False sharing（伪共享）
在做多线程程序的时候，为了避免使用锁，通常会采用这样的数据结构: 根据线程的数目安排一个数组，每个线程用一个元素，互相不冲突。  
但是因为在cpu载入数据时，载入的是一片数据（按cache大小），这样数据离得近的话会把别的核心“专属”数据也一起载入，在运行的时候，cpu需要保证cache数据同步，会反复的载入被其它核心修改过的数据，这会导致严重的性能问题。  

解决方法是，凑够cache line长度（通常是64位）将不同核心操作的数据隔开。  
代码做法可以为成员设置对齐值（alignas或其它）或者用数组扩大数据之间的间隙。

**其它一些内容**
malloc 分配的东西的地址是对齐的：32位为8，64为16。
如果需要定义对齐要用_aligned_malloc分配空间，也可以从一段空间中选择某对齐值的地址来使用。  

可通过内存大小对齐来实现加速，载入时跟cache对齐的话就能马上取到数据，不对齐要进行多一些操作，而且在更新时为了保持数据一致，就会更新多载入（未按cache对齐）的那部分数据。
```
// 如下代码在SMP环境下存在cache频繁刷新问题
double sum = 0.0, sum_local[NUM_THREADS];
#pragma omp parallel num_threads(NUM_THREADS)
{
	// 这里根据线程号取元素
	int me = omp_get_thread_num();
	sum_local[me] = 0.0;

	// 对该位置写
#pragma omp for
	for (i = 0; i < N; i++)
		sum_local[me] += x[i] * y[i];

	// 对该位置读
#pragma omp atomic
	sum += sum_local[me];
}
```
因为sum_local数组是个全局变量, 多个线程都会访问, 并且, 各个线程访问的地方很接近, 会导致一个线程更新, 其他CPU的cache line失效.
所以在尽量不要让更新频率非常高（例如，计数器）和经常访问的变量分布在同一个cache line中，以避免“cache ping-pong”，亦“false sharing”现象。

**无关的一些内容**
**注意位域的操作不是线程安全的，操作时会连带到同属的其它变量**，因为虽然分了几个变量，但是内存位置都一样。宽度为0的未命名位域强制下一位域对齐到其下一类型边界。
